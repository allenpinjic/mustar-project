{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e35296-5c59-4ba7-ad10-14478c646d18",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Implementation of the SPT Model - Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67652c0-2c1c-4acc-84a7-f59bcfef0423",
   "metadata": {},
   "source": [
    "Modifications: Johnny Esteves\\ Author: Allen Pinjic - Created on June 21st, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06998424-0ab3-4d5f-a72b-3a7afa1dcc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<colossus.cosmology.cosmology.Cosmology at 0x7f00b92dc190>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from astropy.io.fits import getdata\n",
    "from astropy.table import Table\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "from colossus.cosmology import cosmology\n",
    "from colossus.lss import mass_function\n",
    "from __future__ import print_function, division\n",
    "cosmology.setCosmology('WMAP9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b1c38b-0352-471f-905f-87f7f3b33625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as plt\n",
    "import pymc3 as pm\n",
    "import aesara\n",
    "import matplotlib.font_manager\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import emcee\n",
    "import pandas as pd\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "164c7db2-ed0d-40da-96df-8f63b2983b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd8246-4e53-46da-b092-9436204d3d38",
   "metadata": {},
   "source": [
    "## Creating a Simple Model via Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdff438a-9b72-477c-bc6c-cf6bfe9ac9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_chisi, sigma_lbd = 0.16, 0.169\n",
    "rho = 0.79\n",
    "Nclusters = 100000\n",
    "\n",
    "# Cluster is defined as Mass (M) and redshift (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42798c1a-76b8-444e-b6a6-23e61fac26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfakes = 10**(np.random.uniform(14,15.2, size=Nclusters))\n",
    "zfakes = np.random.uniform(0.1, 1.3, size=Nclusters)\n",
    "# No \"10^\" for zfakes?\n",
    "# Creating Nclusters number of fake mass \n",
    "# and redshift samples that are uniformly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17754d0-c16a-4de3-bf69-066bc9daa58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _halo_mass_function(M, z):\n",
    "    return mass_function.massFunction(M, z, mdef = '500c', model = 'bocquet16')\n",
    "halo_mass_function = np.vectorize(_halo_mass_function)\n",
    "\n",
    "def E(z):\n",
    "    # The Hubble constant at the value of z\n",
    "    Hz = cosmo.H(z).value\n",
    "    # The Hubble constant at z=0\n",
    "    H0 = cosmo.H(0).value\n",
    "    return (Hz/H0)\n",
    "\n",
    "p_halos = halo_mass_function(mfakes, zfakes)\n",
    "\n",
    "indices_halos = np.random.choice(Nclusters, size = 1000, p = (p_halos/(np.sum(p_halos))))\n",
    "# size = Nclusters/100 or 100,000/100 = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e4b2ce-458c-4402-b759-69a5cbf6f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The creation of the fake samples for redshift and mass\n",
    "# by chnaging the distribution from uniform to parabolic\n",
    "zsims = zfakes[indices_halos]\n",
    "msims = mfakes[indices_halos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f797c9d-297a-4e00-8395-3877cd2f8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "M0 = 3e14\n",
    "Ez0 = E(0)\n",
    "\n",
    "theta = [5.24, 1.534, 0.465, 0.161, 76.9, 1.02, 0.29, 0.16, 0.8]\n",
    "\n",
    "A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "rho = theta[-1]\n",
    "\n",
    "def ln_zeta_given_M(theta_sze,M,z):\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta_sze\n",
    "    return (np.log(A_sze) + (B_sze)*np.log(M/M0) + (C_sze)*(np.log(E(z)/Ez0)))\n",
    "\n",
    "def ln_lbd_given_M(theta_lambda,M,z):\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta_lambda\n",
    "    return (np.log(A_lambda) + (B_lambda)*np.log(M/M0) + (C_lambda)*(np.log(E(z)/Ez0)))\n",
    "\n",
    "def logNormal_variance(mu,std):\n",
    "    return (np.exp(std**2)-1)*np.exp(2*mu+std**2)\n",
    "\n",
    "ln_zeta_true = ln_zeta_given_M([A_sze, B_sze, C_sze, scatter_sze], msims, zsims)\n",
    "ln_lambda_true = ln_lbd_given_M([A_lambda, B_lambda, C_lambda, scatter_lambda], msims, zsims)\n",
    "\n",
    "#mean = [lbd_true, zeta_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2462ecc0-8d54-4231-8f99-adce3676ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between lambda and zeta is 0.95, it should be 0.8\n",
    "# we should add the errors on lambda and zeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31910d76-86ef-4b5e-bd77-26a5d1dc302c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To correlate them:\n",
    "#Cov = np.matrix(([sigma_lbd**2, rho*sigma_lbd*sigma_chisi], [rho*sigma_lbd*sigma_chisi, sigma_lbd**2]))\n",
    "# CHANGE NEEDED IN THE COV?\n",
    "# for a given cluster: msims, zsims\n",
    "\n",
    "#chisi = np.sqrt((np.exp(ln_zeta_true))**2+3)\n",
    "# Where should ln_chisi_true be used below?\n",
    "\n",
    "#lbd_error = np.sqrt(5)/np.sqrt(np.exp(ln_lambda_true))/2\n",
    "\n",
    "#lbd_error = 1/np.sqrt(100) = 0.1 = 10 percent\n",
    "#lbd_error = 1/np.sqrt(_lambda)\n",
    "\n",
    "#ln_lambda, ln_zeta = [], []\n",
    "#for i in range(len(ln_lambda_true)):\n",
    "#    ln_lambdai, ln_zetai = np.random.multivariate_normal([ln_lambda_true[i]+lbd_error[i],ln_zeta_true[i]+chisi],cov=Cov)\n",
    "#    ln_lambda.append(ln_lambdai)\n",
    "#    ln_zeta.append(ln_zetai)\n",
    "    \n",
    "# Final dataset --> (zsims, msims, ln_lambda, ln_zeta, ln_lambda_true, ln_zeta_true)\n",
    "\n",
    "\n",
    "Cov = np.matrix(([sigma_lbd**2, rho*sigma_lbd*sigma_chisi], [rho*sigma_lbd*sigma_chisi, sigma_lbd**2]))\n",
    "\n",
    "# for a given cluster: msims, zsims\n",
    "\n",
    "ln_lambda, ln_zeta = [], []\n",
    "for i in range(len(ln_lambda_true)):\n",
    "    ln_lambdai, ln_zetai = np.random.multivariate_normal([ln_lambda_true[i],ln_zeta_true[i]],cov=Cov)\n",
    "    ln_lambda.append(ln_lambdai)\n",
    "    ln_zeta.append(ln_zetai)\n",
    "    \n",
    "# Final dataset --> (zsims, msims, ln_lambda, ln_zeta, ln_lambda_true, ln_zeta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "239ddd63-5ce7-4f05-be91-a857f5ccf3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the size of the graph and font\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ff49b2e-4dad-4888-9fcb-573a1b2842b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_msims = np.log(msims/M0)\n",
    "\n",
    "#x1 = log_msims\n",
    "#y1 = ln_lambda\n",
    "\n",
    "#f=lambda x,a,b: a*x + b\n",
    "#fit=curve_fit(f, x1, y1)\n",
    "#xsmooth=np.linspace(np.min(x1), np.max(x1), 1000)\n",
    "#plt.plot(x1,y1,'ro',label='Data', alpha = 0.7)\n",
    "#plt.plot(xsmooth,f(xsmooth,*fit[0]),'b-',linewidth=2,label='Logarithmic Fit')\n",
    "#plt.xlabel('Log of Simulated Mass')\n",
    "#plt.ylabel('Log of Richness')\n",
    "#plt.legend()\n",
    "\n",
    "# Unlike the 1-D plot above (simple straight line), this is a vector that\n",
    "# will create a slope which matches the log value from the previously\n",
    "# calculated log of lambda based on the true parameter values\n",
    "# found in (Grandis et al. 2021)\n",
    "\n",
    "# Meant to compare with the simple 1-D plot above and display\n",
    "# whether the simulated data is following the trend set by the real parameter values\n",
    "\n",
    "#plt.plot(x1, ln_lambda_true, 'k--', label='Truth', alpha = 0.8)\n",
    "\n",
    "#print('Combination of Slope and Y-Intercept:', fit[0])\n",
    "#print('Slope:', fit[0][0])\n",
    "#print('Y-Intercept:', fit[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1292f9f-3e58-4005-bd64-20bc566368e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x2 = log_msims\n",
    "#y2 = ln_zeta\n",
    "\n",
    "#f=lambda x,a,b: a*x + b\n",
    "#fit=curve_fit(f, x2, y2)\n",
    "#xsmooth=np.linspace(np.min(x2), np.max(x2), 1000)\n",
    "#plt.plot(x2,y2,'ro',label='Data', alpha = 0.7)\n",
    "#plt.plot(xsmooth,f(xsmooth,*fit[0]),'b-',linewidth=2,label='Logarithmic Fit')\n",
    "#plt.xlabel('Log of Simulated Mass')\n",
    "#plt.ylabel('Log of Redshift')\n",
    "#plt.legend()\n",
    "\n",
    "\n",
    "# Unlike the 1-D plot above (simple straight line), this is a vector that\n",
    "# will create a slope which matches the log value from the previously\n",
    "# calculated log of zeta based on the true parameter values\n",
    "# found in (Grandis et al. 2021)\n",
    "\n",
    "# Meant to compare with the simple 1-D plot above and display\n",
    "# whether the simulated data is following the trend set by the real parameter values\n",
    "\n",
    "#plt.plot(x1, ln_zeta_true, 'k--', label='Truth', alpha = 0.8)\n",
    "\n",
    "#print('Combination of Slope and Y-Intercept:', fit[0])\n",
    "#print('Slope:', fit[0][0])\n",
    "#print('Y-Intercept:', fit[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e00fb02d-d98e-47ca-8802-4db0384273b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            z             M      lambda       zeta  lambda_true  zeta_true\n",
      "0    0.316481  1.587627e+14   50.701638   2.852264    42.046416   2.123088\n",
      "1    0.271402  1.365134e+14   28.244616   1.673184    35.791641   1.665205\n",
      "2    0.356016  7.694109e+14  306.196703  29.580211   211.632753  24.142014\n",
      "3    0.641366  1.710156e+14   49.448419   2.806810    47.863622   2.593742\n",
      "4    0.321785  3.659995e+14   91.881499   8.352681    98.646153   7.655673\n",
      "..        ...           ...         ...        ...          ...        ...\n",
      "995  0.641944  1.372731e+14   36.894000   1.814944    38.255049   1.851715\n",
      "996  0.913352  1.363414e+14   59.701825   2.557670    39.776608   1.972583\n",
      "997  0.266486  1.009999e+14   28.243455   1.157683    26.301498   1.047632\n",
      "998  0.169713  1.355374e+14   39.018022   1.537474    34.991528   1.607091\n",
      "999  0.472253  1.386978e+14   35.691975   1.808865    37.572222   1.797120\n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "out = dict()\n",
    "out['z'] = zsims\n",
    "out['M'] = msims\n",
    "out['lambda'] = np.exp(ln_lambda)\n",
    "out['zeta'] = np.exp(ln_zeta)\n",
    "out['lambda_true'] = np.exp(ln_lambda_true)\n",
    "out['zeta_true'] = np.exp(ln_zeta_true)\n",
    "\n",
    "df = pd.DataFrame(out, columns = ['z', 'M', 'lambda', 'zeta', 'lambda_true', 'zeta_true'])\n",
    "print(df)\n",
    "\n",
    "#df.to_csv('fake_data_Jun21.csv', index=False)\n",
    "# pd.DataFrame.to_csv('fake_data_Jun21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a295c7-cf28-462c-af72-a89c1297f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0 = df.copy()\n",
    "#display(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b135c986-e4fe-42dd-b0af-ba69f65e7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zeta = df0.zeta.to_numpy()\n",
    "#zetacut = zeta > 5\n",
    "#df = df0.loc[zetacut].copy()\n",
    "\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c6c7495-2eed-42c9-b305-396e9c3cc874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r'C:\\MuStar_Project\\mustar-summer-project\\simple_model\\fake_data_Jun21.csv', index=False)\n",
    "df.to_csv('fake_data_Jun21.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76859d0-de42-483f-b3c0-414685846d61",
   "metadata": {},
   "source": [
    "# Creating an MCMC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a39971-5a49-480f-acf7-49864cda3b96",
   "metadata": {},
   "source": [
    "Using the Simple Model Likelihood in order to see how accurate the predicted MCMC values are from the known true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e58268-c814-41fa-b71f-f5fc8a410e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74643df3-dd17-4544-ae95-2e3395301e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ix = np.where((np.array(df['lambda']))>5)[0] # take 100 points\n",
    "#Np = ix.size\n",
    "#yerr = 0.05*(df['lambda'].to_numpy())\n",
    "#redshift = (np.array(df['z']))[ix]\n",
    "#sz_signal = (np.array(df['zeta']))[ix]\n",
    "#_lambda = (np.array(df['lambda']))[ix]\n",
    "#mass = np.array(df['M'])[ix]\n",
    "\n",
    "mask = (df['lambda']>5)&(df['zeta']>3)\n",
    "### Changed the lower limit for zeta from 3 to 5 (since the minimum value setup for zeta is 5) ###\n",
    "### Changed once more to 3 since the number of points dropped to half of its previous size (from ~340 to ~170)\n",
    "### causing the corner plot to be far too inaccurate\n",
    "## Now that the data points have been doubled (to 645) should we be consistent?\n",
    "ix = np.where(mask)[0]\n",
    "Np = ix.size\n",
    "\n",
    "yerr = 0.05*(df['lambda'].to_numpy())\n",
    "\n",
    "redshift = (np.array(df['z']))[ix]\n",
    "sz_signal = (np.array(df['zeta']))[ix]\n",
    "_lambda = (np.array(df['lambda']))[ix]\n",
    "_lambda_error = (np.array(yerr))[ix]\n",
    "mass = (np.array(df['M']))[ix]\n",
    "\n",
    "print('Number of points',Np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268940f-16d7-4650-a54c-d3000e44f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given cluster, i.e. a vector (lbd_hat_i, chisi_i, z_i)\n",
    "# ix = np.arange(len(lambda_chisq))[lambda_chisq>0][np.argmin(sz_signal[lambda_chisq>0])]\n",
    "ix = np.arange(len(np.array(df['lambda'])))[(np.array(df['lambda']))>0][np.argmax(np.array(df['lambda'])[np.array(df['lambda'])>0])]\n",
    "\n",
    "redshift_i = (np.array(df['z']))[ix]\n",
    "print(\"This is the redshift_i:\", redshift_i)\n",
    "sz_signal_i = (np.array(df['zeta']))[ix]\n",
    "print(\"This is the sz_signal_i:\", sz_signal_i)\n",
    "_lambda_i = (np.array(df['lambda']))[ix]\n",
    "print(\"This is the _lambda_i:\", _lambda_i)\n",
    "_lambda_error_i = (np.array(yerr))[ix]\n",
    "print(\"This is the _lambda_error_i:\", _lambda_error_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235c07e-227d-431d-8ca6-e715e9b89665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782da56-bc66-4acb-9098-407bfa8c9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(_lambda_error), _lambda)\n",
    "plt.xlabel('Log of Richness Error')\n",
    "plt.ylabel('Richness')\n",
    "# slope of -1/2.,\n",
    "# plot of lambda vs lambda_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f93e26-906e-4c6d-a671-62a8e0712b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method ='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d78c6c-9e35-41af-81c2-455bef270dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c068e12-1dba-4331-81a0-c1c1e6bc520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.vstack([mass, redshift])\n",
    "print(\"This is the combined x vector of mass and redshift shape:\", x.shape)\n",
    "y = np.vstack([_lambda, sz_signal])\n",
    "print(\"This is the combined y vector of lambda and zeta shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7370fa9-bee5-48bf-9f6d-de99fd291012",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-9\n",
    "lbd = _lambda[0]\n",
    "zeta = sz_signal[0]\n",
    "\n",
    "print(\"This is the first value of lambda:\", lbd)\n",
    "print(\"This is the first value of zeta:\", zeta)\n",
    "\n",
    "theta = [5.24, 1.534, 0.465, 0.161, 76.9, 1.02, 0.29, 0.16, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6489b-0c00-41a5-ae2b-aed0bf9536e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(df['M'][np.array(df['lambda'])>20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2800d-f773-45a8-af8e-a2d3414fd97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTANT CELL ###\n",
    "# set up integration vectors\n",
    "\n",
    "mvec = np.logspace(13.8, 15.5, 150)\n",
    "## TURN ON AND OFF THE MVEC TO TES\n",
    "\n",
    "# lbdvec = np.linspace(3,1.2*np.max(lambda_chisq),150)\n",
    "# zetavec = np.linspace(1,1.1*np.max(sz_signal),75)\n",
    "\n",
    "lbdvec = np.linspace(3, 1.2*np.max(np.array(df['lambda'])), 300)\n",
    "zetavec = np.linspace(1, 1.1*np.max(np.array(df['zeta'])), 150)\n",
    "\n",
    "print('Vector size')\n",
    "print(lbdvec.size)\n",
    "print(zetavec.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ff4a7-a8b5-451f-82ce-6f1ed1268efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTANT CELL ###\n",
    "zvec = np.linspace(np.min(np.array(df['z'])), np.max(np.array(df['z'])), 100)\n",
    "#zvec = np.linspace(np.min(redshift), np.max(redshift), 100)\n",
    "## zzv, mm = np.meshgrid(zvec, mvec)\n",
    "\n",
    "#zzv= np.meshgrid(zvec)\n",
    "## TURN THE ZZV ON AND OFF TO TEST\n",
    "\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d1590-db3b-4c2a-bf91-f2f3f00927f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_array(y,alpha=1e-2):\n",
    "    cy = np.cumsum(y/np.sum(y),axis=0)\n",
    "    ilo,iup = np.interp([alpha,1-alpha],cy,np.arange(len(y))).astype(int)+(0,2)\n",
    "    return ilo, iup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b66f69-4f01-45a7-b0c8-7c380c45f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_chisi(zeta, sz_signal, eps=1e-12):\n",
    "    res = np.exp(-(sz_signal-np.sqrt(zeta**2+2))**2/2.)/np.sqrt(2*np.pi)\n",
    "    return res#np.where(res<eps,0.,res)\n",
    "\n",
    "def gaussian(x,mu,std):\n",
    "    return np.exp(-(x-mu)**2/std**2/2.)/np.sqrt(2*np.pi*std**2)\n",
    "\n",
    "def prob_lbd_hat(x, mean , std, eps=1e-12):\n",
    "    res = gaussian(x, mean , std)\n",
    "    return res#np.where(res<eps,0.,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d50506-fe75-446f-adfe-9ebfbcca9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "prob_lbd_hat_vec = np.array([prob_lbd_hat(lbdvec, _lambda_i, _lambda_error_i)\n",
    "                             for _lambda_i, _lambda_error_i in zip(_lambda, _lambda_error)])\n",
    "print(prob_lbd_hat_vec.shape)\n",
    "print(\"This is prob_lbd_hat_vec :\", prob_lbd_hat_vec)\n",
    "\n",
    "prob_chisi_vec = np.array([prob_chisi(zetavec, sz_signal_i) for sz_signal_i in sz_signal])\n",
    "print(prob_chisi_vec.shape)\n",
    "print(\"This is prob_chisi_vec:\", prob_chisi_vec)\n",
    "\n",
    "\n",
    "lbd_indices_vec = np.array([slice_array(pi, alpha=alpha) for pi in prob_lbd_hat_vec])\n",
    "print(lbd_indices_vec.shape)\n",
    "#print(\"This is lbd_indices_vec:\", lbd_indices_vec)\n",
    "\n",
    "zeta_indices_vec = np.array([slice_array(pi, alpha=alpha) for pi in prob_chisi_vec])\n",
    "print(zeta_indices_vec.shape)\n",
    "#print(\"This is zeta_indices_vec:\", zeta_indices_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d9518-9b62-47ea-a52e-73d915b3e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "\n",
    "# given: mvec, lbdvec and zetavec\n",
    "\n",
    "zz, ll = np.meshgrid(zetavec, lbdvec, indexing='ij')\n",
    "\n",
    "def log_likelihood_vec2(theta, indices, eps=1e-9):\n",
    "    # defining variables\n",
    "    probs = []\n",
    "    for ix in indices:\n",
    "        probs.append(_log_likelihood2(theta, ix))\n",
    "    p = np.array(probs)/np.sum(probs)\n",
    "    log_p = np.log(p)\n",
    "    log_p = np.where(np.isnan(log_p), -np.inf, log_p)\n",
    "    return np.sum(log_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba445b-51c5-4672-85d3-1b823e939a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_likelihood2(theta, ix):\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # forgot the mass\n",
    "    mass_i = mass[ix]\n",
    "    print(\"This is mass_i:\", mass_i)\n",
    "    \n",
    "    redshift_i = redshift[ix]\n",
    "    print(\"This is redshift_i:\", redshift_i)\n",
    "    \n",
    "    p_chisi = prob_chisi_vec[ix]\n",
    "    print(\"This is p_chisi:\", p_chisi)\n",
    "    \n",
    "    p_lbd_hat = prob_lbd_hat_vec[ix]\n",
    "    print(\"This is p_lbd_hat:\", p_lbd_hat)\n",
    "    \n",
    "    llo, lup = list(lbd_indices_vec[ix])\n",
    "    clo, cup = list(zeta_indices_vec[ix])\n",
    "    \n",
    "    print(\"This is the list of lbd_indices_vec[ix]:\", list(lbd_indices_vec[ix]))\n",
    "    print(\"This is the list of zeta_indices_vec[ix]:\", list(zeta_indices_vec[ix]))\n",
    "    \n",
    "    # calling predictions;\n",
    "    ln_lbd_pred = ln_lbd_given_M([A_lambda, B_lambda, C_lambda, scatter_lambda], mass_i, redshift_i)\n",
    "    print(\"This is ln_lbd_pred before lup,llo,cup,clo:\", ln_lbd_pred)\n",
    "    \n",
    "    ln_zeta_pred= ln_zeta_given_M([A_sze, B_sze, C_sze, scatter_sze], mass_i, redshift_i)\n",
    "    print(\"This is ln_zeta_pred before lup,llo,cup,clo:\", ln_zeta_pred)\n",
    "        \n",
    "    #hmf = np.tile(halo_mass_func, (int(lup-llo), int(cup-clo), 1)).T\n",
    "    ln_lbd_pred = np.tile(ln_lbd_pred, (int(lup-llo), int(cup-clo))).T\n",
    "    ln_zeta_pred = np.tile(ln_zeta_pred, (int(lup-llo), int(cup-clo))).T\n",
    "    \n",
    "    print(\"This is ln_lbd_pred after lup,llo,cup,clo:\", ln_lbd_pred)\n",
    "    print(\"This is ln_lbd_pred shape:\", ln_lbd_pred.shape)\n",
    "    print(\"This is ln_zeta_pred after lup,llo,cup,clo:\", ln_zeta_pred)\n",
    "    print(\"This is ln_zeta_pred shape:\", ln_zeta_pred.shape)\n",
    "    \n",
    "    # compute dn_dlbd_dzeta_integrand\n",
    "    # Now p_lbd_zeta instead of p_total_m = compute_dn_dlbd_dzeta_vec2\n",
    "    p_lbd_zeta = compute_dn_dlbd_dzeta_vec2(_lambda_i, _lambda_error_i, sz_signal_i,\n",
    "                                           scatter_lambda, scatter_sze, rho,\n",
    "                                           ll[clo:cup,llo:lup],zz[clo:cup,llo:lup],\n",
    "                                           ln_lbd_pred, ln_zeta_pred)\n",
    "    print(\"This is p_lbd_zeta:\", p_lbd_zeta)\n",
    "\n",
    "    # integrate over zeta\n",
    "    p_chisi = np.tile(p_chisi[clo:cup], (int(lup-llo), 1)).T\n",
    "    print(\"This is p_chisi:\", p_chisi)\n",
    "    ## REMOVE ADDITIONAL VALUE OF 1\n",
    "    \n",
    "    p_lbd = np.trapz(p_lbd_zeta*p_chisi, x=zetavec[clo:cup], axis=0)\n",
    "    print(\"This is p_lbd after trapezoidal transformation:\", p_lbd)\n",
    "\n",
    "    # integrate over lambda\n",
    "    p = np.trapz(p_lbd*p_lbd_hat[llo:lup], x=lbdvec[llo:lup], axis=0)\n",
    "    print(\"This is p after trapezoidal transformation:\", p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041e17f-a86c-47ed-ad53-ae3e594aab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dn_dlbd_dzeta_vec2(_lambda_i, _lambda_error_i, sz_signal_i, scatter_lambda, scatter_sze, rho,\n",
    "                               lvec, zvec, ln_lbd_pred, ln_zeta_pred, eps = 1e-9):\n",
    "    \n",
    "    # converting std to normal distribution\n",
    "    s_zeta = logNormal_variance(ln_zeta_pred, scatter_sze)\n",
    "    #print(\"This is ln_zeta_pred (1):\", ln_zeta_pred)\n",
    "    #print(\"This is scatter_sze (2):\", scatter_sze)\n",
    "    print(\"This is s_zeta (3):\", s_zeta)\n",
    "    s_zeta_inv = np.where(s_zeta<=eps, -np.inf, 1/s_zeta)\n",
    "    print(\"This is s_zeta_inv:\", s_zeta_inv)\n",
    "    s_lambda = logNormal_variance(ln_lbd_pred, scatter_lambda)\n",
    "    #print(\"This is ln_lbd_pred (1):\", ln_lbd_pred)\n",
    "    #print(\"This is scatter_lambda (2):\", scatter_lambda)\n",
    "    print(\"This is s_lambda (3):\", s_lambda)\n",
    "    s_lambda_inv = np.where(s_lambda<=eps, -np.inf, 1/s_lambda)\n",
    "    print(\"This is s_lambda_inv:\", s_lambda_inv)\n",
    "    \n",
    "    cov = (scatter_lambda)**(2)*(scatter_sze)**(2)*(1-rho**2)\n",
    "    print(\"This is cov matrix:\", cov)\n",
    "    additional_cov = (-0.5)*np.log(np.pi*cov**2)\n",
    "    print(\"This is additional_cov:\", additional_cov)\n",
    "    \n",
    "    # avoid error messages\n",
    "    rho_inv = (1-rho**2)\n",
    "    rho_inv = np.where(rho_inv<=eps, -np.inf, 1/rho_inv)\n",
    "    \n",
    "    lbd_std = (np.log(lvec) - (ln_lbd_pred))*s_lambda_inv\n",
    "    print(\"This is lbd_std:\", lbd_std)\n",
    "    zeta_std = (np.log(zvec)- (ln_zeta_pred))*s_zeta_inv\n",
    "    print(\"This is zeta_std:\", zeta_std)\n",
    "    np.seterr(invalid='ignore')\n",
    "\n",
    "    # lbd_likelihood\n",
    "    lp_lbd  = (-rho_inv*lbd_std**2)/2\n",
    "    print(\"This is lp_lbd:\", lp_lbd)\n",
    "\n",
    "    # zeta likelihood\n",
    "    lp_zeta = (-rho_inv*zeta_std**2)/2\n",
    "    print(\"This is lp_zeta:\", lp_zeta)\n",
    "    \n",
    "    # corr likelihod\n",
    "    lp_corr = rho*rho_inv*lbd_std*zeta_std\n",
    "    print(\"This is lp_corr:\", lp_corr)\n",
    "\n",
    "    lp_total_m = lp_lbd + lp_zeta + lp_corr + additional_cov\n",
    "    print(\"This is lp_total_m:\", lp_total_m)\n",
    "    \n",
    "    p_total_m = (np.exp(lp_total_m))/(lvec*zvec)\n",
    "    print(\"This is p_total_m:\", p_total_m)\n",
    "    \n",
    "    return p_total_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b4ce3-0b33-47da-81d9-2c2a585d6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rho = theta[-1]\n",
    "#scatter_sze = theta[3]\n",
    "#scatter_lambda = theta[7]\n",
    "\n",
    "SZ_Priors = {'A_sze':[5.24, 0.85], 'B_sze':[1.534, 0.100],'C_sze':[0.465, 0.407],\n",
    "             'scatter_sze':[0.161, 0.080]}\n",
    "\n",
    "sz_theta_values = ['A_sze', 'B_sze', 'C_sze', 'scatter_sze']\n",
    "\n",
    "Lambda_Priors = {'A_lambda':[76.9, 8.2], 'B_lambda':[1.020, 0.080],'C_lambda':[0.23, 0.16],\n",
    "             'scatter_lambda':[0.23, 0.16]}\n",
    "\n",
    "lambda_theta_values = ['A_lambda', 'B_lambda', 'C_lambda', 'scatter_lambda']\n",
    "\n",
    "\n",
    "\n",
    "def set_gaussian_prior(param, mu, sigma):\n",
    "    return -0.5*((param - mu)/(sigma))**2\n",
    "\n",
    "# Setting SZE priors\n",
    "def set_prior_sze(theta_values):\n",
    "    lp = 0.\n",
    "    rhomin = 0.\n",
    "    rhomax = 1.\n",
    "    \n",
    "    for i, prior_name in enumerate(['A_sze', 'B_sze', 'C_sze', 'scatter_sze']):\n",
    "        mean, error = SZ_Priors[prior_name]\n",
    "        param = theta_values[i]\n",
    "        result = set_gaussian_prior(param, mean, error)\n",
    "        lp += np.where(np.abs(result)>9., -np.inf, result)\n",
    "        # outside a range of six sigmas (six standard deviations)\n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if (theta_values[-1] > 0) else -np.inf\n",
    "    return lp\n",
    "\n",
    "# Setting Lambda priors\n",
    "def set_prior_lambda(theta_values):\n",
    "    lp = 0.\n",
    "    rhomin = 0.\n",
    "    rhomax = 1.\n",
    "    \n",
    "    for i, prior_name in enumerate(['A_lambda', 'B_lambda', 'C_lambda', 'scatter_lambda']):\n",
    "        mean, error = Lambda_Priors[prior_name]\n",
    "        param = theta_values[i]\n",
    "        result = set_gaussian_prior(param, mean, error)\n",
    "        lp += np.where(np.abs(result)>9., -np.inf, result)\n",
    "        # outside a range of six sigmas (six standard deviations)\n",
    "       \n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if (theta_values[-1] > 0) else -np.inf\n",
    "    return lp\n",
    "\n",
    "def logprior(theta):\n",
    "    lp = 0\n",
    "    \n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    lp_lambda = set_prior_lambda([A_lambda, B_lambda, C_lambda, scatter_lambda])\n",
    "    lp_sze = set_prior_sze([A_sze, B_sze, C_sze, scatter_sze])\n",
    "    \n",
    "    lp = 0. if ((rho > 0) and (rho < 1)) else -np.inf\n",
    "    return lp + lp_lambda + lp_sze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aec883-93f0-46ad-88a3-598dd3b01465",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430a71a-c5b9-41eb-8b9c-f58a9f064db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logposterior(theta, indices):\n",
    "    lp = logprior(theta)\n",
    "    \n",
    "    # if the prior is not finite return a probability of zero (log probability of -inf)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    \n",
    "    # return the likeihood times the prior (log likelihood plus the log prior)\n",
    "    return lp + log_likelihood_vec2(theta, indices, eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496141a5-ac6b-4c95-b469-c818f3f8fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_prior_sze([5.24, 1.534, 0.465, 0.161])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8d709-2692-4667-b39e-40dc8ef65345",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nburnin = 1300 # number of burn-in samples\n",
    "Nsamples = 2000 # number of final posterior samples\n",
    "walkers = 150\n",
    "ndims = len(theta)\n",
    "\n",
    "guess = (np.array(theta)[:, np.newaxis]*(1.+0.01*np.random.normal(size=(ndims,walkers)))).T\n",
    "\n",
    "# set additional args for the posterior (the data, the noise std. dev., and the abscissa)\n",
    "sel = np.arange(len(redshift))#[:100]\n",
    "sel = np.random.randint(len(redshift), size=100, dtype=int)\n",
    "argslist = [sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b9443-1e1a-42bd-95ee-b62f69051f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logposterior(theta, sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f7852-2857-43ec-be00-b38307f3a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "np.random.seed(42)\n",
    "nll = lambda *args: -log_likelihood_vec2(*args)\n",
    "initial = theta + 0.1 * np.random.randn(9)\n",
    "soln = minimize(nll, initial, args=sel)\n",
    "albd, blbd, clbd, slbd, rho = soln.x[4:]\n",
    "\n",
    "print(\"Maximum likelihood estimates:\")\n",
    "print(\"Albd = {0:.3f}\".format(albd))\n",
    "print(\"Blbd = {0:.3f}\".format(blbd))\n",
    "print(\"Clbd = {0:.3f}\".format(clbd))\n",
    "print(\"Scatter_lbd = {0:.3f}\".format(slbd))\n",
    "print(\"rho: {0:.3f}\".format(rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50f7e4-996a-4bba-999e-7a0ddeb27a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25335428-4186-40e9-bcef-adc398ac761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soln.x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1d77f-6536-48f4-b2b1-139d05434536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "#from multiprocessing import Pool\n",
    "\n",
    "#pool = Pool(processes=64)              # start 64 worker processes\n",
    "#sampler = emcee.EnsembleSampler(walkers, ndims, logposterior,args=[np.arange(len(mass))], pool=pool)\n",
    "#start = time.time()\n",
    "#sampler.run_mcmc(guess, Nsamples+Nburnin)\n",
    "#end = time.time()\n",
    "#multi_time = end - start\n",
    "#serial_time = (1.5)*(3600)\n",
    "#print(\"Multiprocessing took {0:.1f} seconds\".format(multi_time))\n",
    "#print(\"{0:.1f} times faster than serial\".format(serial_time / multi_time))\n",
    "\n",
    "# Replaced \"args=[np.arange(len(mass))]\" with \"args=argslist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf599675-a40e-4872-9c6d-8f34bcb768b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat_samples = sampler.flatchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c7a2ba-e574-47f8-95a0-6191f9683075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(ndims, figsize=(10, 7), sharex=True)\n",
    "#samples = flat_samples\n",
    "#for i in range(ndims):\n",
    "#    ax = axes[i]\n",
    "#    ax.plot(samples[:, i], \"k\", alpha=0.3)\n",
    "#    ax.set_xlim(0, len(samples))\n",
    "    #ax.set_ylabel(labels[i])\n",
    "#    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "#axes[-1].set_xlabel(\"step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329d7d4-6e44-4456-8061-6250571f0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import corner\n",
    "\n",
    "#fig = corner.corner(\n",
    "#    flat_samples, truths=theta\n",
    "#);\n",
    "\n",
    "#fig = corner.corner(\n",
    "#    flat_samples, \n",
    "#    truths= theta,\n",
    "#    labels=[r\"Aλ\", r\"Bλ\", r\"Cλ\", r\"Scatter\", r\"A_SZE\", r\"B_SZE\", r\"C_SZE\", r\"Scatter_SZE\", \"ρ\"], \n",
    "#    show_titles = True\n",
    "#);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271544a-7b0a-4f47-b343-d8ae69d2fb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73651d19-9af6-4f46-8cc3-a8ebb812606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the sampler\n",
    "#sampler = emcee.EnsembleSampler(walkers, ndims, logposterior, args=argslist)\n",
    "\n",
    "# pass the initial samples and total number of samples required\n",
    "#sampler.run_mcmc(guess, Nsamples+Nburnin);\n",
    "\n",
    "# extract the samples (removing the burn-in)\n",
    "#postsamples = sampler.chain[:, Nburnin:, :].reshape((-1, ndims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623a59f-f9b8-46d3-a21c-07f23c473256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    import matplotlib as mpl\n",
    "#    mpl.use(\"Agg\") # force Matplotlib backend to Agg\n",
    "#    import corner # import corner.py\n",
    "#except ImportError:\n",
    "#    sys.exit(1)\n",
    "#\n",
    "#print('Number of posterior samples is {}'.format(postsamples.shape[0]))\n",
    "#\n",
    "#fig = corner.corner(postsamples, labels=[r\"Aλ\", r\"Bλ\", r\"Cλ\", r\"Scatter\", r\"A_SZE\", r\"B_SZE\", r\"C_SZE\", r\"Scatter_SZE\", \"ρ\"]\n",
    "#                    , show_titles = True, truths=[A_lambda, B_lambda, C_lambda, scatter_lambda,\n",
    "#                                                  A_sze, B_sze, C_sze, scatter_sze, rho])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
