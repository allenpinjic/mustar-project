{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ba72a5-0920-4a0b-bfed-abec27784405",
   "metadata": {},
   "source": [
    "# Implementation of the SPT Model - Version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751efd9-a0cf-48f4-bb14-6ed4cc93c40d",
   "metadata": {},
   "source": [
    "Modifications: Johnny Esteves\\ Author: Allen Pinjic - Created on June 9th, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b67b118-6baf-42e4-85cd-3f402b550992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io.fits import getdata\n",
    "from astropy.table import Table\n",
    "from astropy.cosmology import WMAP9 as cosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789e852-91de-4be5-ba85-81769d90a1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as plt\n",
    "import pymc3 as pm\n",
    "import aesara\n",
    "import matplotlib.font_manager\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6095267-781d-42ac-9e3a-affe663606df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadb57e-9435-4cb1-ba63-e6a2ea6967c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../data_set/sptecs_catalog_oct919.fits'\n",
    "\n",
    "data = Table(getdata(fname))\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3a6b7-9e9b-4c7d-8b99-8688213e4c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_signal = np.array(data['XI'])\n",
    "lambda_chisq = np.array(data['LAMBDA_CHISQ'])\n",
    "lambda_chisqE = np.array(data['LAMBDA_CHISQ_E'])\n",
    "redshift = np.array(data['REDSHIFT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ce73c-9676-4ae2-858e-f6349c44adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also called lambda hat (as shown in the paper)\n",
    "## Shows the measured cluster richness whose values are over 20\n",
    "\n",
    "plt.hist(np.log10(data['M500'][lambda_chisq>20]*1e14))\n",
    "# Why not display values that are over 40\n",
    "# \"Cross matching studies, we restrict ourselves to the joint DESY1 x SPT-SZ footprint and to ðœ† >Ë† 40\"\n",
    "# \"We match the ðœ† > Ë† 40 redMaPPer sample with the SPT-SZ sample selected above SZE signal to noise ðœ‰ > 4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1f5ea-e884-46f4-b1f1-9ae5686c9a8b",
   "metadata": {},
   "source": [
    "Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20de24-750b-47af-8e34-5bbe15072bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colossus.cosmology import cosmology\n",
    "from colossus.lss import mass_function\n",
    "cosmology.setCosmology('WMAP9')\n",
    "\n",
    "def _halo_mass_function(M, z):\n",
    "    return mass_function.massFunction(M, z, mdef = '500c', model = 'bocquet16')\n",
    "halo_mass_function = np.vectorize(_halo_mass_function)\n",
    "\n",
    "def E(z):\n",
    "    # The Hubble constant at the value of z\n",
    "    Hz = cosmo.H(z).value\n",
    "    # The Hubble constant at z=0\n",
    "    H0 = cosmo.H(0).value\n",
    "    return (Hz/H0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721fba0-c698-49b7-aefd-4be1f4fa333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogNormal models\n",
    "# see https://en.wikipedia.org/wiki/Log-normal_distribution\n",
    "M0 = 3e14\n",
    "Ez0 = E(0)\n",
    "\n",
    "#Insert the priors on the SZE scaling relation parameters that identify with SZE,\n",
    "# along with a value for the mass (M) and redshift (z)\n",
    "## References Equation 2\n",
    "def ln_zeta_given_M(theta_sze,M,z):\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta_sze\n",
    "    return np.log(A_sze) + (B_sze)*np.log(M/M0) + (C_sze)*(np.log(E(z)/Ez0))\n",
    "\n",
    "#Insert the priors on the SZE scaling relation parameters that identify with LAMBDA, \n",
    "# along with a value for the mass (M) and redshift (z)\n",
    "# Identified with the \n",
    "## References Equation 3\n",
    "def ln_lbd_given_M(theta_lambda,M,z):\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta_lambda\n",
    "    return np.log(A_lambda) + (B_lambda)*np.log(M/M0) + (C_lambda)*(np.log(E(z)/Ez0))\n",
    "\n",
    "#Insert the value of the mean and standard deviation as the two parameters\n",
    "# to find the log of the variance in a normal distribution\n",
    "def logNormal_variance(mu,std):\n",
    "    return (np.exp(std**2)-1)*np.exp(2*mu+std**2)\n",
    "# the linear relation lnLbd and lnZeta are logNormal\n",
    "# the scatter of a logNormal is different from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798c471-1cca-4724-9027-b63e8f25c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up integration vectors\n",
    "mvec = np.logspace(13.8, 15.5, 75)\n",
    "lbdvec = np.linspace(3,1.2*np.max(lambda_chisq),150)\n",
    "zetavec = np.linspace(1,1.1*np.max(sz_signal),75)\n",
    "# lbdvec = np.exp(np.arange(np.log(5),np.log(1.2*np.max(lambda_chisq)),0.032))\n",
    "# zetavec = np.exp(np.arange(np.log(1),np.log(1.1*np.max(sz_signal)),0.045))\n",
    "\n",
    "print('Vector size')\n",
    "print(mvec.size)\n",
    "print(lbdvec.size)\n",
    "print(zetavec.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b33b87-ecc2-4c91-9087-4c3eb4321f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zvec = np.linspace(0., 1.3, 100)\n",
    "zzv, mm = np.meshgrid(zvec, mvec)\n",
    "from scipy import interpolate\n",
    "halo_mass_function2 = interpolate.interp1d(zvec, halo_mass_function(mm, zzv), kind='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f371d021-0d39-4fe5-9b8b-07bdac5d9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only points with a significant p_chisi/lbd_hat\n",
    "\n",
    "def slice_array(y,alpha=1e-2):\n",
    "    cy = np.cumsum(y/np.sum(y),axis=0)\n",
    "    ilo,iup = np.interp([alpha,1-alpha],cy,np.arange(len(y))).astype(int)+(0,2)\n",
    "    return ilo, iup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748783c-9f7e-4f1d-b79b-e737e06e19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "\n",
    "# given: mvec, lbdvec and zetavec\n",
    "\n",
    "mm, zz, ll = np.meshgrid(mvec, zetavec, lbdvec, indexing='ij')\n",
    "\n",
    "def log_likelihood_vec2(theta, z, y, yerr, eps=1e-9):\n",
    "    # defining variables\n",
    "    lbd_hat, chisi = y[0], y[1]\n",
    "    lbd_err = yerr\n",
    "    probs = []\n",
    "    for lbd_hat_i, lbd_err_i, chisi_i, z_i in zip(lbd_hat, lbd_err, chisi, z):\n",
    "        probs.append(_log_likelihood2(theta, lbd_hat_i, lbd_err_i, chisi_i, z_i))    \n",
    "    p = np.array(probs)/np.sum(probs)\n",
    "    return np.sum(np.log(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f4e72-e5b4-494a-a524-ebab97451eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_likelihood2(theta, lbd_hat_i, lbd_err_i, chisi_i, z_i):\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # calling predictions;\n",
    "    ln_lbd_pred = ln_lbd_given_M([A_lambda, B_lambda, C_lambda, scatter_lambda], mvec, z_i)\n",
    "    ln_zeta_pred= ln_zeta_given_M([A_sze, B_sze, C_sze, scatter_sze], mvec, z_i)\n",
    "    halo_mass_func = halo_mass_function2(z_i)\n",
    "    \n",
    "    # error probabilities\n",
    "    p_chisi = prob_chisi(zetavec, chisi_i)\n",
    "    p_lbd_hat = prob_lbd_hat(lbdvec, lbd_hat_i, lbd_err_i)\n",
    "    \n",
    "    # take only significant p_lbd_hat values\n",
    "    llo, lup = slice_array(p_lbd_hat,alpha=1e-4)\n",
    "    clo, cup = slice_array(p_chisi,alpha=1e-4)\n",
    "    \n",
    "    hmf = np.tile(halo_mass_func, (int(lup-llo), int(cup-clo), 1)).T\n",
    "    ln_lbd_pred = np.tile(ln_lbd_pred, (int(lup-llo), int(cup-clo), 1)).T\n",
    "    ln_zeta_pred = np.tile(ln_zeta_pred, (int(lup-llo), int(cup-clo), 1)).T\n",
    "    \n",
    "    # compute dn_dlbd_dzeta_integrand\n",
    "    p_total_m = compute_dn_dlbd_dzeta_vec2(lbd_hat_i, lbd_err_i, chisi_i,\n",
    "                                           scatter_lambda, scatter_sze, rho,\n",
    "                                           ll[:,clo:cup,llo:lup],zz[:,clo:cup,llo:lup],\n",
    "                                           ln_lbd_pred, ln_zeta_pred, hmf)\n",
    "    # integrate over M\n",
    "    p_lbd_zeta = np.trapz(p_total_m, x=mvec, axis=0)\n",
    "\n",
    "    # integrate over zeta\n",
    "    p_chisi = np.tile(p_chisi[clo:cup], (int(lup-llo), 1)).T\n",
    "    p_lbd = np.trapz(p_lbd_zeta*p_chisi, x=zetavec[clo:cup], axis=0)\n",
    "\n",
    "    # integrate over lambda\n",
    "    p = np.trapz(p_lbd*p_lbd_hat[llo:lup], x=lbdvec[llo:lup], axis=0)\n",
    "    return p#np.log(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db8658-093f-475f-8689-359528c6eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dn_dlbd_dzeta_vec2(lbd_hat_i, lbd_err_i, chisi_i, scatter_lambda, scatter_sze, rho,\n",
    "                               lvec, zvec, ln_lbd_pred, ln_zeta_pred, hmf):\n",
    "    # converting std to normal distribution\n",
    "    s_zeta = logNormal_variance(ln_zeta_pred, scatter_sze)\n",
    "    s_lambda = logNormal_variance(ln_lbd_pred, scatter_lambda)\n",
    "    \n",
    "    # avoid error messages\n",
    "    rho_inv = (1-rho**2)\n",
    "    rho_inv = np.where(rho_inv<=eps, -np.inf, 1/rho_inv)\n",
    "\n",
    "    # defining standirized variables\n",
    "    lbd_std = (lvec - np.exp(ln_lbd_pred))/s_lambda\n",
    "    zeta_std = (zvec - np.exp(ln_zeta_pred))/s_zeta\n",
    "\n",
    "    # lbd_likelihood\n",
    "    lp_lbd  = -rho_inv*lbd_std**2/2\n",
    "\n",
    "    # zeta likelihood\n",
    "    lp_zeta = -rho_inv*zeta_std**2/2\n",
    "\n",
    "    # corr likelihod\n",
    "    lp_corr = rho*rho_inv*lbd_std*zeta_std\n",
    "\n",
    "    lp_total_m = lp_lbd+lp_zeta+lp_corr\n",
    "    p_total_m = np.exp(lp_total_m)*hmf\n",
    "    return p_total_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121f172-a87f-4d02-aa7c-ae409a55e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the log_likelihood_vec2 in the emcee code\n",
    "# via writing to the prior functions.\n",
    "\n",
    "# In reference to rho's (Ï) defintion it states:\n",
    "# Parameters of the richnessâ€“mass relation defined\n",
    "# in Eq. 11 (Bleem et al. 2019) \n",
    "## and the correlation coefficient, ÏSZâˆ’Î», between the SZ signal (Î¶) and richness.\n",
    "\n",
    "# Ï also defined as the correlation coefficient  \n",
    "# that encodes the degree of correlation between the intrinsic scatters on the respective observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6538934-dfa5-4f8a-b4e5-04d147449a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Np = 10\n",
    "ix = np.where(lambda_chisq>30)[0][:Np] # take 10 points\n",
    "\n",
    "z = redshift[ix]\n",
    "chisi = sz_signal[ix]\n",
    "lbd_hat = lambda_chisq[ix]\n",
    "lbd_err = lambda_chisqE[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0290b9-d273-45a8-8ee7-c98d7a28055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given cluster, i.e. a vector (lbd_hat_i, chisi_i, z_i)\n",
    "\n",
    "# ix = np.arange(len(lambda_chisq))[lambda_chisq>0][np.argmin(sz_signal[lambda_chisq>0])]\n",
    "ix = np.arange(len(lambda_chisq))[lambda_chisq>0][np.argmax(lambda_chisq[lambda_chisq>0])]\n",
    "\n",
    "lbd_hat_i = lambda_chisq[ix]\n",
    "lbd_err_i = lambda_chisqE[ix]\n",
    "chisi_i = sz_signal[ix]\n",
    "z_i = redshift[ix]\n",
    "print(lbd_hat_i)\n",
    "print(chisi_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ba249-741b-4175-b800-3c9d4a8fb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function \n",
    "# debuging here\n",
    "eps  =1e-9\n",
    "lbd  = lbd_hat[0]\n",
    "zeta = chisi[0]\n",
    "\n",
    "theta = [5.24, 1.534, 0.465, 0.161, 76.9, 1.02, 0.29, 0.16, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8ecf9-d84f-44ed-88c9-8d0a4750c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# import emcee\n",
    "import emcee\n",
    "\n",
    "## HOW TO: Directly implement data\n",
    "\n",
    "# MAIN QUESTIONS:\n",
    "# 2. How to make logprior for both scatter_sze and scatter_lambda since\n",
    "# they act like rho (then again, why would that make creating a logprior function for them not possible?)\n",
    "\n",
    "### LAMBDA PRIORS ###\n",
    "\n",
    "def logprior_A_lbd(theta):  \n",
    "    lp = 0.\n",
    "    \n",
    "    # unpack the model parameters from the tuple\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # uniform prior on c\n",
    "    rhomin = 0. # lower range of prior (rho)\n",
    "    rhomax = 1.  # upper range of prior (rho)\n",
    "    \n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if ((rhomin < rho < rhomax) and (scatter_sze > 0) and (scatter_lambda > 0)) else -np.inf\n",
    "    \n",
    "    # Gaussian prior on A_lambda\n",
    "    A_lambda_mu = __    # mean of the Gaussian prior\n",
    "    A_lambda_sigma = __ # standard deviation of the Gaussian prior\n",
    "    lp -= 0.5*((A_lambda - A_lambda_mu)/A_lambda_sigma)**2\n",
    "    \n",
    "    return lp\n",
    "\n",
    "def logprior_B_lbd(theta):  \n",
    "    lp = 0.\n",
    "    \n",
    "    # unpack the model parameters from the tuple\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # uniform prior on c\n",
    "    rhomin = 0. # lower range of prior (rho)\n",
    "    rhomax = 1.  # upper range of prior (rho)\n",
    "    \n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if ((rhomin < rho < rhomax) and (scatter_sze > 0) and (scatter_lambda > 0)) else -np.inf\n",
    "    \n",
    "    # Gaussian prior on A_lambda\n",
    "    B_lambda_mu = __    # mean of the Gaussian prior\n",
    "    B_lambda_sigma = __ # standard deviation of the Gaussian prior\n",
    "    lp -= 0.5*((B_lambda - B_lambda_mu)/B_lambda_sigma)**2\n",
    "    \n",
    "    return lp\n",
    "\n",
    "def logprior_C_lbd(theta):  \n",
    "    lp = 0.\n",
    "    \n",
    "    # unpack the model parameters from the tuple\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # uniform prior on c\n",
    "    rhomin = 0. # lower range of prior (rho)\n",
    "    rhomax = 1.  # upper range of prior (rho)\n",
    "    \n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if ((rhomin < rho < rhomax) and (scatter_sze > 0) and (scatter_lambda > 0)) else -np.inf\n",
    "    \n",
    "    # Gaussian prior on A_lambda\n",
    "    C_lambda_mu = __    # mean of the Gaussian prior\n",
    "    C_lambda_sigma = __ # standard deviation of the Gaussian prior\n",
    "    lp -= 0.5*((C_lambda - C_lambda_mu)/C_lambda_sigma)**2\n",
    "    \n",
    "    return lp\n",
    "\n",
    "def logprior_scatter_lbd(theta):  \n",
    "    lp = 0.\n",
    "    \n",
    "    # unpack the model parameters from the tuple\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # uniform prior on c\n",
    "    rhomin = 0. # lower range of prior (rho)\n",
    "    rhomax = 1.  # upper range of prior (rho)\n",
    "    \n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if ((rhomin < rho < rhomax) and (scatter_sze > 0) and (scatter_lambda > 0)) else -np.inf\n",
    "    \n",
    "    # Gaussian prior on A_lambda\n",
    "    scatter_lambda_mu = __    # mean of the Gaussian prior\n",
    "    scatter_lambda_sigma = __ # standard deviation of the Gaussian prior\n",
    "    lp -= 0.5*((scatter_lambda - scatter_lambda_mu)/scatter_lambda_sigma)**2\n",
    "    \n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81414e7-b993-49bb-aa33-18c614e0a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SZE PRIORS ###\n",
    "def logprior_A_sze(theta):  \n",
    "    lp = 0.\n",
    "    \n",
    "    # unpack the model parameters from the tuple\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # uniform prior on c\n",
    "    rhomin = 0. # lower range of prior (rho)\n",
    "    rhomax = 1.  # upper range of prior (rho)\n",
    "    \n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if ((rhomin < rho < rhomax) and (scatter_sze > 0) and (scatter_lambda > 0)) else -np.inf\n",
    "    \n",
    "    # Gaussian prior on A_lambda\n",
    "    A_sze_mu = __    # mean of the Gaussian prior\n",
    "    A_sze_sigma = __ # standard deviation of the Gaussian prior\n",
    "    lp -= 0.5*((A_sze - A_sze_mu)/A_sze_sigma)**2\n",
    "\n",
    "    \n",
    "def logprior_B_sze(theta):  \n",
    "    lp = 0.\n",
    "    \n",
    "    # unpack the model parameters from the tuple\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # uniform prior on c\n",
    "    rhomin = 0. # lower range of prior (rho)\n",
    "    rhomax = 1.  # upper range of prior (rho)\n",
    "    \n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if ((rhomin < rho < rhomax) and (scatter_sze > 0) and (scatter_lambda > 0)) else -np.inf\n",
    "    \n",
    "    # Gaussian prior on A_lambda\n",
    "    B_sze_mu = __    # mean of the Gaussian prior\n",
    "    B_sze_sigma = __ # standard deviation of the Gaussian prior\n",
    "    lp -= 0.5*((B_sze - B_sze_mu)/B_sze_sigma)**2\n",
    "\n",
    "def logprior_C_sze(theta):  \n",
    "    lp = 0.\n",
    "    \n",
    "    # unpack the model parameters from the tuple\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # uniform prior on c\n",
    "    rhomin = 0. # lower range of prior (rho)\n",
    "    rhomax = 1.  # upper range of prior (rho)\n",
    "    \n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if ((rhomin < rho < rhomax) and (scatter_sze > 0) and (scatter_lambda > 0)) else -np.inf\n",
    "    \n",
    "    # Gaussian prior on A_lambda\n",
    "    C_sze_mu = __    # mean of the Gaussian prior\n",
    "    C_sze_sigma = __ # standard deviation of the Gaussian prior\n",
    "    lp -= 0.5*((C_sze - C_sze_mu)/C_sze_sigma)**2\n",
    "\n",
    "def logprior_scatter_sze(theta):  \n",
    "    lp = 0.\n",
    "    \n",
    "    # unpack the model parameters from the tuple\n",
    "    # unfolding theta\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # uniform prior on c\n",
    "    rhomin = 0. # lower range of prior (rho)\n",
    "    rhomax = 1.  # upper range of prior (rho)\n",
    "    \n",
    "    # set prior to 1 (log prior to 0) if in the range and zero (-inf) outside the range \n",
    "    lp = 0. if ((rhomin < rho < rhomax) and (scatter_sze > 0) and (scatter_lambda > 0)) else -np.inf\n",
    "    \n",
    "    # Gaussian prior on A_lambda\n",
    "    scatter_sze_mu = __    # mean of the Gaussian prior\n",
    "    scatter_sze_sigma = __ # standard deviation of the Gaussian prior\n",
    "    lp -= 0.5*((scatter_sze - scatter_sze_mu)/scatter_sze_sigma)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de0d21-ac32-4ba3-aaf7-ee0896856124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(theta, lbd_hat_i, lbd_err_i, chisi_i, z_i):\n",
    "    # Imported the parameters of Johnny's _log_likelihood2 since they\n",
    "    # match the emcee template\n",
    "    # 1. theta = theta\n",
    "    # 2. data = lbd_hat_i\n",
    "    # 3. sigma (standard deviation) = lbd_err_i\n",
    "    # Why include chisi_i and z_i?\n",
    "    \"\"\"\n",
    "    The natural logarithm of the joint likelihood.\n",
    "    \n",
    "    Args:\n",
    "        theta (tuple): a sample containing individual parameter values\n",
    "        data (list): the set of data/observations\n",
    "        sigma (float): the standard deviation of the data points\n",
    "        x (list): the abscissa values at which the data/model is defined\n",
    "    \n",
    "    Note:\n",
    "        We do not include the normalisation constants (as discussed above).\n",
    "    \"\"\"\n",
    "    \n",
    "    # unpack the model parameters from the tuple\n",
    "    A_lambda, B_lambda, C_lambda, scatter_lambda = theta[4:8]\n",
    "    A_sze, B_sze, C_sze, scatter_sze = theta[:4]\n",
    "    rho = theta[-1]\n",
    "    \n",
    "    # evaluate the model (assumes that the straight_line model is defined as above)\n",
    "    md = straight_line(x, m, c)\n",
    "    ### Which variables should I include in this statement above?\n",
    "    \n",
    "    # return the log likelihood\n",
    "    return -0.5*np.sum(((md - lbd_hat_i)/(lbd_err_i))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db76f1-255a-4904-ae34-102363af1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logposterior(theta, lbd_hat_i, lbd_err_i, chisi_i, z_i):\n",
    "    \"\"\"\n",
    "    The natural logarithm of the joint posterior.\n",
    "    \n",
    "    Args:\n",
    "        theta (tuple): a sample containing individual parameter values\n",
    "        data (list): the set of data/observations\n",
    "        sigma (float): the standard deviation of the data points\n",
    "        x (list): the abscissa values at which the data/model is defined\n",
    "    \"\"\"\n",
    "    \n",
    "    lp = logprior(theta) # get the prior\n",
    "    \n",
    "    # if the prior is not finite return a probability of zero (log probability of -inf)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    \n",
    "    # return the likeihood times the prior (log likelihood plus the log prior)\n",
    "    return  lp + loglikelihood(theta, lbd_hat_i, lbd_err_i, chisi_i, z_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d298ed-fa53-4182-9e13-c3c39d9e7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nens = 100   # number of ensemble points\n",
    "\n",
    "rhomin = 0.  # lower range of prior\n",
    "rhomax = 1.   # upper range of prior\n",
    "\n",
    "mmu = 0.     # mean of the Gaussian prior\n",
    "msigma = 10. # standard deviation of the Gaussian prior\n",
    "\n",
    "mini = np.random.normal(mmu, msigma, Nens) # initial m points\n",
    "cini = np.random.uniform(rhomin, rhomax, Nens) # initial c points\n",
    "\n",
    "## How to create the initial points for our data?\n",
    "## Initial points for each prior? \n",
    "## Should each prior have a '_ini' function? If so, then what should its parameters be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a23ecd-6736-481a-871b-dc8bd7d18991",
   "metadata": {},
   "outputs": [],
   "source": [
    "inisamples = np.array([mini, cini]).T # initial samples\n",
    "\n",
    "ndims = inisamples.shape[1] # number of parameters/dimensions\n",
    "\n",
    "Nburnin = 500   # number of burn-in samples\n",
    "Nsamples = 500  # number of final posterior samples\n",
    "\n",
    "# set additional args for the posterior (the data, the noise std. dev., and the abscissa)\n",
    "argslist = (theta, lbd_hat_i, lbd_err_i, chisi_i, z_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22187126-fcec-4bf3-9295-4b4e5471eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the sampler\n",
    "sampler = emcee.EnsembleSampler(Nens, ndims, logposterior, args=argslist)\n",
    "\n",
    "# pass the initial samples and total number of samples required\n",
    "sampler.run_mcmc(inisamples, Nsamples+Nburnin);\n",
    "\n",
    "# extract the samples (removing the burn-in)\n",
    "postsamples = sampler.chain[:, Nburnin:, :].reshape((-1, ndims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460c2dd-f1cc-4a6e-ba95-85cfc8e7e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib as mpl\n",
    "    mpl.use(\"Agg\") # force Matplotlib backend to Agg\n",
    "    import corner # import corner.py\n",
    "except ImportError:\n",
    "    sys.exit(1)\n",
    "\n",
    "print('Number of posterior samples is {}'.format(postsamples.shape[0]))\n",
    "\n",
    "fig = corner.corner(postsamples, labels=[r\"$m$\", r\"$c$\"], truths=[m, c])\n",
    "fig.savefig('emcee.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
